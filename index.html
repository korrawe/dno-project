<!DOCTYPE html>
<html>
<head>

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-K6ZT9FLT77"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-K6ZT9FLT77');
  </script>

  <meta charset="utf-8">
  <meta name="description"
        content="DNO: Optimizing Diffusion Noise Can Serve As Universal Motion Priors">
  <meta name="keywords" content="DNO, diffusion noise optimization, diffusion latent space, human motion, motion synthesis">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>DNO: Optimizing Diffusion Noise Can Serve As Universal Motion Priors</title>


  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="shortcut icon" href="favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="publication-header">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">DNO: Optimizing Diffusion Noise Can Serve As Universal Motion Priors</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://korrawe.github.io/">Korrawe Karunratanakul</a><sup>1</sup>,</span> 
            <span class="author-block">
              <a href="https://konpat.me/">Konpat Preechakul</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://emreaksan.github.io/">Emre Aksan</a><sup>4</sup>,
            </span>
            <br>
            <span class="author-block">
              <a href="https://thabobeeler.com/">Thabo Beeler</a><sup>4</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.supasorn.com/">Supasorn Suwajanakorn</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://vlg.inf.ethz.ch/team/Prof-Dr-Siyu-Tang.html">Siyu Tang</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>ETH Zurich </span> &nbsp &nbsp
            <span class="author-block"><sup>2</sup>UC Berkeley </span>  <br>
            <span class="author-block"><sup>3</sup>VISTEC, Thailand</span> &nbsp &nbsp
            <span class="author-block"><sup>4</sup>Google</span>
            <!-- <span class="author-block"><sup>1</sup>ETH Zurich</span> -->
          </div>

          <!-- <h3 class="is-5 conference">ICCV 2023</h3> -->

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/abs/2212."
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2305.12577"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv (coming soon)</span>
                </a>
              </span>
              <!-- Video Link. --> 
              <span class="link-block">
                <a href="https://youtu.be/heWXQdIjSzs" 
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/korrawe/Diffusion-Noise-Optimization"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (To be released)</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/teaser.jpg"
                 class="column is-centered has-text-centered"
                 alt="Teaser image."/>

      <!-- <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video> -->
      <h2 class="subtitle has-text-centered">
        <b> Diffusion Noise Optimization (DNO) </b> can leverage the existing human motion diffusion models as universal
        motion priors. We demonstrate its capability in the motion editing tasks where DNO can preserve the content of the original model and
        accommodates a diverse range of editing modes, including changing trajectory, pose, joint location, and avoiding newly added obstacles.
      </h2>
    </div>
  </div>
</section>



<!-- <section class="section"> -->
<section class="hero is-light is-small">
  <div class="container is-max-desktop">
    <br>
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We propose Diffusion Noise Optimization (DNO), a new method that effectively leverages existing motion diffusion models as motion priors for a wide range of motion-related tasks.
          </p>
          <p>
            Instead of training a task-specific diffusion model for each new task, DNO operates by optimizing the diffusion latent noise of an existing pre-trained text-to-motion model.
            Given the corresponding latent noise of a human motion, it propagates the gradient from the target criteria defined on the motion space through the whole denoising process to update the diffusion latent noise. As a result, DNO supports any use cases where criteria can be defined as a function of motion. 
          </p>
          <p>
            In particular, we show that, for motion editing and control, DNO outperforms existing methods in both achieving the objective and preserving the motion content. 
            DNO accommodates a diverse range of editing modes, including changing trajectory, pose, joint locations, or avoiding newly added obstacles.
          </p>
          <p>
            In addition, DNO is effective in motion denoising and completion, producing smooth and realistic motion from noisy and partial inputs.
            DNO achieves these results at inference time without the need for model retraining, offering great versatility for any defined reward or loss function on the motion representation.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/heWXQdIjSzs?si=QDc62aFZW8uLj-e3"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
  <br/>
</section>
<!-- <iframe width="560" height="315" src="https://www.youtube.com/embed/heWXQdIjSzs?si=QDc62aFZW8uLj-e3" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe> -->


<section class="section">
  <div class="container is-max-desktop">
    <!-- Summary -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Summary</h2>
        <div class="content has-text-justified">
          <h4>Key Ideas</h4>
          We show that the diffusion latent noise (x<sub>T</sub>) can be optimized using critertion function defined on the motion space (x<sub>0</sub>) to serve as universal motion priors for a wide range of motion-related tasks.

          <!-- <figure  class="content has-text-centered">
            <img src="./static/images/guidance_problem.jpg"
                   class="column is-7 is-offset-1 has-text-centered"
                   alt="Guidance problem."
                   />
          </figure > -->
          <p>
          <h4>Casual Summary</h4>
          <p>
            Many papers show that in VAE or GAN, we can optimize the latent noise according to a loss in the output space to obtain a prediction that satisfies certain properties.

            Then, what about the (supposedly) richer generative space of the diffusion model? Can we optimize it the same way we do with VAE or GAN?
          </p>

          <p>
            In this paper, we show we can <b>also change the output motion by optimizing the latent diffusion noise</b>. This latent noise is very versatile as a motion prior.
          </p>

          <b>How?</b> We unroll the ODE chain to produce the output motion, compute loss, and backpropagate the gradient through the full denoising chain to the latent noise x<sub>T</sub>.
          We demonstrate that this process is feasible.  In addition, we do not need that many ODE steps for the optimization in the motion domain, which we can still hold in the GPU memory.
          <br>

          This enables us to use a pre-trained motion diffusion model to handle many arbitrary motion tasks, including motion editing, in-betweening, denoising, and avoiding obstacles, by only changing the objective function during test time optimization. The model is never trained to solve any of these tasks.

          <figure  class="content has-text-centered">
            <img src="./static/images/overview.jpg"
                   class="column is-10 is-offset-0 has-text-centered"
                   alt="Method Overview."
                   />
          </figure >
          <figure  class="content has-text-centered">
            <img src="./static/images/DNO_pipeline.jpg"
                   class="column is-6 is-offset-0 has-text-centered"
                   alt="DNO pipeline Overview."
                   />
          </figure >
          </p>
        </div>
        
      </div>
    </div>

    <!-- Pipeline
    <div class="columns is-centered has-text-centered">
      
    </div> -->
    
    <!-- <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Hand Avatar</h2>

        <h3 class="title is-4">Robustness</h3>
        <div class="content has-text-justified">
          <p>
            Given a short video, HARP can create an avatar from different capturing scenarios.
          </p>
        </div>
        <div class="content has-text-centered">
          <img src="./static/images/other_dataset.jpg"
                 class="column is-centered has-text-centered"
                 alt="results in different dataset."/>
        </div>
        <br/>

        <h3 class="title is-4">Out-of-distribution appearance</h3>
        <div class="content has-text-justified">
          <p>
            HARP works without modification for out-of-distribution appearance that cannot be captured by parametric models.
          </p>
        </div>
        <div class="content has-text-centered">
          <img src="./static/images/tattoo_single.jpg"
                 class="column is-centered has-text-centered"
                 alt="Out-of-distribution result."/>
        </div>


      </div>
    </div> -->



  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <br>
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3">Results</h2>
      <br>
    </div>
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-4">DNO does not require any training <span style="color:#6C91C2";><b>(zero-shot)</b></span> <br> 
        and works with <span style="color:#6C91C2";><b>any</b></span> motion task by changing the criterion function.</h2>
    </div>    
    <br>
    <br>

    <!-- Motion Editing -->
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-4">Motion Editing</h2>
      <br>
    </div>
    <div class="columns is-centered has-text-centered">
      <h4 class="subtitle is-4">With DNO, we can edit the <span style="color:#5d88bc";>original motions</span> to produce <span style="color:#d6960b";>output motions</span> <br> that satisfy given objectives while keeping the original content intact.</h4>
    </div>

    <div class="content has-text-centered">
      <video id="replay-video"
              autoplay  
              controls
              muted
              preload
              loop
              playsinline
              width="1000">
              <!-- height="100%"> -->
        <source src="./static/videos/edit_jump.mp4"
                type="video/mp4">
      </video>
    </div>

    <div class="content has-text-centered">
      <video id="replay-video"
              autoplay  
              controls
              muted
              preload
              loop
              playsinline
              width="896">
              <!-- height="100%"> -->
        <source src="./static/videos/edit_render.mp4"
                type="video/mp4">
      </video>
    </div>

    <!-- carousel -->
    <!-- <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item 4602">
          <video poster="" id="pelvis" autoplay controls muted loop height="100%">
            <source src="./static/videos/inbetween_sit.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item 559">
          <video poster="" id="pelvis1" autoplay controls muted loop height="100%">
            <source src="./static/videos/inbetween_sit.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item 277">
          <video poster="" id="pelvis2" autoplay controls muted loop height="100%">
            <source src="./static/videos/inbetween_sit.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item 100">
          <video poster="" id="pelvis3" autoplay controls muted loop height="100%">
            <source src="./static/videos/inbetween_sit.mp4"
                    type="video/mp4">
        </video>
        </div>
      </div>
    </div>
    <br> -->

    <!-- Side by side -->
    <!-- <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column">
          <div class="content">
            <video id="inbetween_sit" autoplay controls muted loop height="100%" width="448">
              <source src="./static/videos/inbetween_sit.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
        <div class="column">
          <div class="columns is-centered">
            <div class="column content">
              <video id="inbetween_walk" autoplay controls muted loop height="100%" width="448">
                <source src="./static/videos/inbetween_walk.mp4"
                        type="video/mp4">
              </video>
            </div>

          </div>
        </div>
      </div>
    </div>
    <br> -->
    <br>
    <!-- Motion Editing -->

    <!-- Motion In-betweening -->
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-4">Motion In-betweening</h2>
    </div>
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column">
          <div class="content">
            <!-- <h2 class="title is-3">Header1</h2> -->
            <video id="inbetween_sit" autoplay controls muted loop height="100%" width="448">
              <source src="./static/videos/inbetween_sit.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
        <div class="column">
          <!-- <h2 class="title is-3">Header2</h2> -->
          <div class="columns is-centered">
            <div class="column content">
              <video id="inbetween_walk" autoplay controls muted loop height="100%" width="448">
                <source src="./static/videos/inbetween_walk.mp4"
                        type="video/mp4">
              </video>
            </div>

          </div>
        </div>
      </div>
    </div>
    <br>
    <br>
    <!-- Motion In-betweening -->

    <!-- Motion Denoising -->
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-4">Motion Denoising</h2>
    </div>

    <!-- carousel -->
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item 100">
          <video poster="" id="pelvis3" autoplay controls muted loop height="100%">
            <source src="./static/videos/refine_8.mp4"
                    type="video/mp4">
        </video>
        </div>
        <div class="item 4602">
          <video poster="" id="pelvis" autoplay controls muted loop height="100%">
            <source src="./static/videos/refine_10.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item 559">
          <video poster="" id="pelvis1" autoplay controls muted loop height="100%">
            <source src="./static/videos/refine_11.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item 277">
          <video poster="" id="pelvis2" autoplay controls muted loop height="100%">
            <source src="./static/videos/refine_13.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item 100">
          <video poster="" id="pelvis3" autoplay controls muted loop height="100%">
            <source src="./static/videos/refine_6.mp4"
                    type="video/mp4">
        </video>
        </div>
      </div>
    </div>

    <!-- <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column">
          <div class="content"> -->
            <!--  <h2 class="title is-3">Header1</h2> -->
            <!-- <video id="inbetween_sit" autoplay controls muted loop height="100%" width="448">
              <source src="./static/videos/refine_10.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
        <div class="column"> -->
          <!-- <h2 class="title is-3">Header2</h2> -->
          <!-- <div class="columns is-centered">
            <div class="column content">
              <video id="inbetween_walk" autoplay controls muted loop height="100%" width="448">
                <source src="./static/videos/refine_11.mp4"
                        type="video/mp4">
              </video>
            </div>

          </div>
        </div>
      </div>
    </div>
    <br> -->
    <br>
    <!-- Motion Motion Denoising -->

    <!-- Motion Blending -->
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-4">Motion Blending</h2>
      <br>
    </div>
    <div class="columns is-centered has-text-centered">
      <h4 class="subtitle is-4">DNO can blend two motions (<span style="color:#5d88bc";>blue</span> and <span style="color:#3e7929";>green</span>) to produce motion with <span style="color:#d6960b";>smooth transition</span> between them.</h4>
    </div>


    <div class="container is-max-desktop">
      <!-- <div class="columns is-centered"> -->
        <!-- <div class="column"> -->
          <div class="content">
            <!-- <h2 class="title is-3">Header1</h2> -->
            <video id="inbetween_sit" autoplay controls muted loop height="100%" height="448">
              <source src="./static/videos/blend_1_combine.mp4"
                      type="video/mp4">
            </video>
          </div>
        <!-- </div> -->
        <!-- <div class="column"> -->
          <!-- <h2 class="title is-3">Header2</h2> -->
          <!-- <div class="columns is-centered"> -->
            <!-- <div class="column content"> -->
            <div class="content has-text-centered">
              <video id="inbetween_walk" autoplay controls muted loop height="100%" height="448">
                <source src="./static/videos/blend_jump_jack_combine.mp4"
                        type="video/mp4">
              </video>
            </div>

          <!-- </div> -->
        <!-- </div> -->
      <!-- </div> -->
    </div>
    <!-- Motion Blending -->

    </div>
  </div>
  <br>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{karunratanakul2023dno,
  title={Optimizing Diffusion Noise Can Serve As Universal Motion Priors},
  author={Karunratanakul, Korrawe and Preechakul, Konpat and Aksan, Emre and Beeler, Thabo and Suwajanakorn, Supasorn and Tang, Siyu},
  booktitle={arxiv},
  year={2023}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <!-- <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div> -->
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            We use the website template provided by <a
              href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
